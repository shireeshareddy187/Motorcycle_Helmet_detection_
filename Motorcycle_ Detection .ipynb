{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "notebook126448b0dc.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shireeshareddy187/Motorcycle_Helmet_detection_/blob/main/Motorcycle_%20Detection%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from six.moves.urllib.request import urlopen\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-01-06T05:07:06.839135Z",
          "iopub.execute_input": "2022-01-06T05:07:06.839898Z",
          "iopub.status.idle": "2022-01-06T05:07:13.183570Z",
          "shell.execute_reply.started": "2022-01-06T05:07:06.839850Z",
          "shell.execute_reply": "2022-01-06T05:07:13.182481Z"
        },
        "trusted": true,
        "id": "9puTDH2u6sSc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the tensorflow models repository\n",
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "execution": {
          "iopub.status.busy": "2022-01-06T05:07:13.186568Z",
          "iopub.execute_input": "2022-01-06T05:07:13.187149Z",
          "iopub.status.idle": "2022-01-06T05:07:34.160330Z",
          "shell.execute_reply.started": "2022-01-06T05:07:13.187095Z",
          "shell.execute_reply": "2022-01-06T05:07:34.158859Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht33yuCB6sSh",
        "outputId": "60912b4c-66ad-4757-a214-07e465ff75c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3159, done.\u001b[K\n",
            "remote: Counting objects: 100% (3159/3159), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2689/2689), done.\u001b[K\n",
            "remote: Total 3159 (delta 810), reused 1327 (delta 426), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3159/3159), 33.40 MiB | 26.03 MiB/s, done.\n",
            "Resolving deltas: 100% (810/810), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "sudo apt install -y protobuf-compiler\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install .\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T05:07:34.162394Z",
          "iopub.execute_input": "2022-01-06T05:07:34.162749Z",
          "iopub.status.idle": "2022-01-06T05:07:56.850566Z",
          "shell.execute_reply.started": "2022-01-06T05:07:34.162712Z",
          "shell.execute_reply": "2022-01-06T05:07:56.847038Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df609a1r6sSh",
        "outputId": "6dcf03da-8cc3-4b2f-f641-ee50784874b7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Processing /content/models/research\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.35.0-cp37-cp37m-manylinux2010_x86_64.whl (9.9 MB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.24)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.3)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.7.0-py2.py3-none-any.whl (1.8 MB)\n",
            "Collecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.0-py2.py3-none-any.whl (213 kB)\n",
            "Requirement already satisfied: tensorflow>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Collecting tensorflow-text>=2.7.0\n",
            "  Downloading tensorflow_text-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.7 MB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.8)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.53.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.6)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.13.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.22.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.10.0.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (12.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.42.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.6.5-cp37-cp37m-manylinux_2_24_x86_64.whl (247 kB)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.1)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
            "Collecting fastavro<2,>=0.21.4\n",
            "  Downloading fastavro-1.4.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
            "Collecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.19.8-py3-none-any.whl (45 kB)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Collecting protobuf>=3.12.0\n",
            "  Downloading protobuf-3.19.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.4.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.4.0)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1683460 sha256=cd5328e3264d35969248577d0c53b61187c45504c255fc44ddd1911ec21816c9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t2h_gdjx/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n",
            "  Building wheel for py-cpuinfo (setup.py): started\n",
            "  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22258 sha256=066da8f37a11c8bd62c2b8647449545a02612ab468b195942bb475eb3790f238\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for dill (setup.py): started\n",
            "  Building wheel for dill (setup.py): finished with status 'done'\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78546 sha256=b99d38a4e41fb8255077718f39456021d4f351cf0e9475b71ddfb8ccc8f934f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py): started\n",
            "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44009 sha256=34f44e437f059ede0d4dec3dd6f66adea0f13c50f1bbde8dd4f6470e9f39adab\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=e3b246085bfdb6fc9ec2f791b6c9cd13b939ce3025a9434e14013670f0630ac9\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n",
            "Installing collected packages: requests, protobuf, tensorflow-io-gcs-filesystem, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.22.0\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.22.0:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.22.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed apache-beam-2.35.0 avro-python3-1.10.2 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.8 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.62 orjson-3.6.5 portalocker-2.3.2 proto-plus-1.19.8 protobuf-3.19.1 py-cpuinfo-8.0.0 pyyaml-6.0 requests-2.27.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.15.0 tensorflow-io-0.23.1 tensorflow-io-gcs-filesystem-0.23.1 tensorflow-model-optimization-0.7.0 tensorflow-text-2.7.3 tf-models-official-2.7.0 tf-slim-1.1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T05:07:56.851549Z",
          "iopub.status.idle": "2022-01-06T05:07:56.852016Z"
        },
        "trusted": true,
        "id": "ZNt6vQeI6sSi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# patch tf1 into `utils.ops`\n",
        "utils_ops.tf = tf.compat.v1\n",
        "\n",
        "# Patch the location of gfile\n",
        "tf.gfile = tf.io.gfile"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T05:07:56.853104Z",
          "iopub.status.idle": "2022-01-06T05:07:56.853556Z"
        },
        "trusted": true,
        "id": "de5oFNUB6sSi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir labels"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T05:07:56.854497Z",
          "iopub.status.idle": "2022-01-06T05:07:56.854973Z"
        },
        "trusted": true,
        "id": "RlIcwXQW6sSj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile xml_to_csv.py\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            # print('MEMBER', member)\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     int(member[5][0].text),\n",
        "                     int(member[5][1].text),\n",
        "                     int(member[5][2].text),\n",
        "                     int(member[5][3].text)\n",
        "                     )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "\n",
        "\n",
        "def main():\n",
        "    # for folder in ['train','test']:\n",
        "    for folder in ['../input/helmet-detection/annotations']:\n",
        "        # image_path = os.path.join(os.getcwd(), ('images/' + folder))\n",
        "        # xml_df = xml_to_csv(image_path)\n",
        "        xml_df = xml_to_csv(folder)\n",
        "        # xml_df.to_csv(('labels/' + folder + '_labels.csv'), index=None)\n",
        "        xml_df.to_csv(('labels/' + 'labels.csv'), index=None)\n",
        "        print('Successfully converted xml to csv.')\n",
        "\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T05:07:56.856249Z",
          "iopub.status.idle": "2022-01-06T05:07:56.856683Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-Ths3n66sSj",
        "outputId": "e4a57654-230c-4d6c-b3e5-c2ba885beb63"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing xml_to_csv.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python xml_to_csv.py"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T05:07:56.857918Z",
          "iopub.status.idle": "2022-01-06T05:07:56.858373Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiahCPWI6sSk",
        "outputId": "67c0491e-1d69-446e-ce23-4e04ee969de2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully converted xml to csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile generate_tfrecord.py\n",
        "\"\"\"\n",
        "Usage:\n",
        "  # From tensorflow/models/\n",
        "  # Create train data:\n",
        "  python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record\n",
        "\n",
        "  # Create test data:\n",
        "  python generate_tfrecord.py --csv_input=images/test_labels.csv  --image_dir=images/test --output_path=test.record\n",
        "\"\"\"\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "flags = tf.app.flags\n",
        "flags.DEFINE_string('csv_input', '', 'Path to the CSV input')\n",
        "flags.DEFINE_string('image_dir', '', 'Path to the image directory')\n",
        "flags.DEFINE_string('output_path', '', 'Path to output TFRecord')\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "# TO-DO replace this with label map\n",
        "def class_text_to_int(row_label):\n",
        "    if row_label == 'With Helmet': # names should exactly match with the CSV file label names\n",
        "        return 1\n",
        "    elif row_label == 'Without Helmet': # names should exactly match with the CSV file label names\n",
        "        return 2\n",
        "    else:\n",
        "        None\n",
        "\n",
        "\n",
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    width, height = image.size\n",
        "\n",
        "    filename = group.filename.encode('utf8')\n",
        "    image_format = b'png'\n",
        "    xmins = []\n",
        "    xmaxs = []\n",
        "    ymins = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for index, row in group.object.iterrows():\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(row['class'].encode('utf8'))\n",
        "        classes.append(class_text_to_int(row['class']))\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "\n",
        "def main(_):\n",
        "    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)\n",
        "    path = os.path.join(os.getcwd(), FLAGS.image_dir)\n",
        "    examples = pd.read_csv(FLAGS.csv_input)\n",
        "    grouped = split(examples, 'filename')\n",
        "    for group in grouped:\n",
        "        tf_example = create_tf_example(group, path)\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "\n",
        "    writer.close()\n",
        "    output_path = os.path.join(os.getcwd(), FLAGS.output_path)\n",
        "    print('Successfully created the TFRecords: {}'.format(output_path))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tf.app.run()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T05:07:56.859694Z",
          "iopub.status.idle": "2022-01-06T05:07:56.860180Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWnuMOpg6sSl",
        "outputId": "d22b2c5d-f545-49cf-cbc1-c4b92722a9ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing generate_tfrecord.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_tfrecord.py --csv_input=labels/labels.csv --image_dir=../input/helmet-detection/images --output_path=train.record"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T05:07:56.861063Z",
          "iopub.status.idle": "2022-01-06T05:07:56.861496Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNCrA2eD6sSm",
        "outputId": "ed9890cf-9fe4-452e-df0d-fd54e4528d57"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecords: /content/train.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T05:07:56.862689Z",
          "iopub.status.idle": "2022-01-06T05:07:56.863149Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIyXG06v6sSm",
        "outputId": "31b60882-a023-400b-fb15-6dfa57405ad8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-06 05:47:58--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 108.177.111.128, 2607:f8b0:4001:c07::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|108.177.111.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 244817203 (233M) [application/x-tar]\n",
            "Saving to: ‘ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_resnet50_v1_fpn 100%[===================>] 233.48M   259MB/s    in 0.9s    \n",
            "\n",
            "2022-01-06 05:47:59 (259 MB/s) - ‘ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [244817203/244817203]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T05:07:56.864237Z",
          "iopub.status.idle": "2022-01-06T05:07:56.864698Z"
        },
        "trusted": true,
        "id": "k1l32Im-6sSm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_main_tf2.py\n",
        "# Lint as: python3\n",
        "# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "r\"\"\"Creates and runs TF2 object detection models.\n",
        "For local training/evaluation run:\n",
        "PIPELINE_CONFIG_PATH=path/to/pipeline.config\n",
        "MODEL_DIR=/tmp/model_outputs\n",
        "NUM_TRAIN_STEPS=10000\n",
        "SAMPLE_1_OF_N_EVAL_EXAMPLES=1\n",
        "python model_main_tf2.py -- \\\n",
        "  --model_dir=$MODEL_DIR --num_train_steps=$NUM_TRAIN_STEPS \\\n",
        "  --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \\\n",
        "  --pipeline_config_path=$PIPELINE_CONFIG_PATH \\\n",
        "  --alsologtostderr\n",
        "\"\"\"\n",
        "from absl import flags\n",
        "import tensorflow.compat.v2 as tf\n",
        "from object_detection import model_lib_v2\n",
        "\n",
        "flags.DEFINE_string('pipeline_config_path', None, 'Path to pipeline config '\n",
        "                    'file.')\n",
        "flags.DEFINE_integer('num_train_steps', None, 'Number of train steps.')\n",
        "flags.DEFINE_bool('eval_on_train_data', False, 'Enable evaluating on train '\n",
        "                  'data (only supported in distributed training).')\n",
        "flags.DEFINE_integer('sample_1_of_n_eval_examples', None, 'Will sample one of '\n",
        "                     'every n eval input examples, where n is provided.')\n",
        "flags.DEFINE_integer('sample_1_of_n_eval_on_train_examples', 5, 'Will sample '\n",
        "                     'one of every n train input examples for evaluation, '\n",
        "                     'where n is provided. This is only used if '\n",
        "                     '`eval_training_data` is True.')\n",
        "flags.DEFINE_string(\n",
        "    'model_dir', None, 'Path to output model directory '\n",
        "                       'where event and checkpoint files will be written.')\n",
        "flags.DEFINE_string(\n",
        "    'checkpoint_dir', None, 'Path to directory holding a checkpoint.  If '\n",
        "    '`checkpoint_dir` is provided, this binary operates in eval-only mode, '\n",
        "    'writing resulting metrics to `model_dir`.')\n",
        "\n",
        "flags.DEFINE_integer('eval_timeout', 3600, 'Number of seconds to wait for an'\n",
        "                     'evaluation checkpoint before exiting.')\n",
        "\n",
        "flags.DEFINE_bool('use_tpu', False, 'Whether the job is executing on a TPU.')\n",
        "flags.DEFINE_string(\n",
        "    'tpu_name',\n",
        "    default=None,\n",
        "    help='Name of the Cloud TPU for Cluster Resolvers.')\n",
        "flags.DEFINE_integer(\n",
        "    'num_workers', 1, 'When num_workers > 1, training uses '\n",
        "    'MultiWorkerMirroredStrategy. When num_workers = 1 it uses '\n",
        "    'MirroredStrategy.')\n",
        "flags.DEFINE_integer(\n",
        "    'checkpoint_every_n', 1000, 'Integer defining how often we checkpoint.')\n",
        "flags.DEFINE_boolean('record_summaries', True,\n",
        "                     ('Whether or not to record summaries during'\n",
        "                      ' training.'))\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "def main(unused_argv):\n",
        "  flags.mark_flag_as_required('model_dir')\n",
        "  flags.mark_flag_as_required('pipeline_config_path')\n",
        "  tf.config.set_soft_device_placement(True)\n",
        "\n",
        "  if FLAGS.checkpoint_dir:\n",
        "    model_lib_v2.eval_continuously(\n",
        "        pipeline_config_path=FLAGS.pipeline_config_path,\n",
        "        model_dir=FLAGS.model_dir,\n",
        "        train_steps=FLAGS.num_train_steps,\n",
        "        sample_1_of_n_eval_examples=FLAGS.sample_1_of_n_eval_examples,\n",
        "        sample_1_of_n_eval_on_train_examples=(\n",
        "            FLAGS.sample_1_of_n_eval_on_train_examples),\n",
        "        checkpoint_dir=FLAGS.checkpoint_dir,\n",
        "        wait_interval=300, timeout=FLAGS.eval_timeout)\n",
        "  else:\n",
        "    if FLAGS.use_tpu:\n",
        "      # TPU is automatically inferred if tpu_name is None and\n",
        "      # we are running under cloud ai-platform.\n",
        "      resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\n",
        "          FLAGS.tpu_name)\n",
        "      tf.config.experimental_connect_to_cluster(resolver)\n",
        "      tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "      strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "    elif FLAGS.num_workers > 1:\n",
        "      strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
        "    else:\n",
        "      strategy = tf.compat.v2.distribute.MirroredStrategy()\n",
        "\n",
        "    with strategy.scope():\n",
        "      model_lib_v2.train_loop(\n",
        "          pipeline_config_path=FLAGS.pipeline_config_path,\n",
        "          model_dir=FLAGS.model_dir,\n",
        "          train_steps=FLAGS.num_train_steps,\n",
        "          use_tpu=FLAGS.use_tpu,\n",
        "          checkpoint_every_n=FLAGS.checkpoint_every_n,\n",
        "          record_summaries=FLAGS.record_summaries)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  tf.compat.v1.app.run()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T05:07:56.865863Z",
          "iopub.status.idle": "2022-01-06T05:07:56.866315Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6VspJLY6sSm",
        "outputId": "b5087a5d-851c-405b-8799-0dbdffd6ef35"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model_main_tf2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile labelmap.pbtxt\n",
        "item {\n",
        "  id: 1\n",
        "  name: 'With Helmet'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 2\n",
        "  name: 'Wihout Helmet'\n",
        "}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T05:07:56.867239Z",
          "iopub.status.idle": "2022-01-06T05:07:56.867695Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUvqb8Bm6sSn",
        "outputId": "5554b8c2-5eb5-466e-e395-09a0b42f3cb9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing labelmap.pbtxt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile pipeline.config\n",
        "model {\n",
        "  ssd {\n",
        "    num_classes: 2\n",
        "    image_resizer {\n",
        "      fixed_shape_resizer {\n",
        "        height: 640\n",
        "        width: 640\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: \"ssd_resnet50_v1_fpn_keras\"\n",
        "      depth_multiplier: 1.0\n",
        "      min_depth: 16\n",
        "      conv_hyperparams {\n",
        "        regularizer {\n",
        "          l2_regularizer {\n",
        "            weight: 0.00039999998989515007\n",
        "          }\n",
        "        }\n",
        "        initializer {\n",
        "          truncated_normal_initializer {\n",
        "            mean: 0.0\n",
        "            stddev: 0.029999999329447746\n",
        "          }\n",
        "        }\n",
        "        activation: RELU_6\n",
        "        batch_norm {\n",
        "          decay: 0.996999979019165\n",
        "          scale: true\n",
        "          epsilon: 0.0010000000474974513\n",
        "        }\n",
        "      }\n",
        "      override_base_feature_extractor_hyperparams: true\n",
        "      fpn {\n",
        "        min_level: 3\n",
        "        max_level: 7\n",
        "      }\n",
        "    }\n",
        "    box_coder {\n",
        "      faster_rcnn_box_coder {\n",
        "        y_scale: 10.0\n",
        "        x_scale: 10.0\n",
        "        height_scale: 5.0\n",
        "        width_scale: 5.0\n",
        "      }\n",
        "    }\n",
        "    matcher {\n",
        "      argmax_matcher {\n",
        "        matched_threshold: 0.5\n",
        "        unmatched_threshold: 0.5\n",
        "        ignore_thresholds: false\n",
        "        negatives_lower_than_unmatched: true\n",
        "        force_match_for_each_row: true\n",
        "        use_matmul_gather: true\n",
        "      }\n",
        "    }\n",
        "    similarity_calculator {\n",
        "      iou_similarity {\n",
        "      }\n",
        "    }\n",
        "    box_predictor {\n",
        "      weight_shared_convolutional_box_predictor {\n",
        "        conv_hyperparams {\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "              weight: 0.00039999998989515007\n",
        "            }\n",
        "          }\n",
        "          initializer {\n",
        "            random_normal_initializer {\n",
        "              mean: 0.0\n",
        "              stddev: 0.009999999776482582\n",
        "            }\n",
        "          }\n",
        "          activation: RELU_6\n",
        "          batch_norm {\n",
        "            decay: 0.996999979019165\n",
        "            scale: true\n",
        "            epsilon: 0.0010000000474974513\n",
        "          }\n",
        "        }\n",
        "        depth: 256\n",
        "        num_layers_before_predictor: 4\n",
        "        kernel_size: 3\n",
        "        class_prediction_bias_init: -4.599999904632568\n",
        "      }\n",
        "    }\n",
        "    anchor_generator {\n",
        "      multiscale_anchor_generator {\n",
        "        min_level: 3\n",
        "        max_level: 7\n",
        "        anchor_scale: 4.0\n",
        "        aspect_ratios: 1.0\n",
        "        aspect_ratios: 2.0\n",
        "        aspect_ratios: 0.5\n",
        "        scales_per_octave: 2\n",
        "      }\n",
        "    }\n",
        "    post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 9.99999993922529e-09\n",
        "        iou_threshold: 0.6000000238418579\n",
        "        max_detections_per_class: 100\n",
        "        max_total_detections: 100\n",
        "        use_static_shapes: false\n",
        "      }\n",
        "      score_converter: SIGMOID\n",
        "    }\n",
        "    normalize_loss_by_num_matches: true\n",
        "    loss {\n",
        "      localization_loss {\n",
        "        weighted_smooth_l1 {\n",
        "        }\n",
        "      }\n",
        "      classification_loss {\n",
        "        weighted_sigmoid_focal {\n",
        "          gamma: 2.0\n",
        "          alpha: 0.25\n",
        "        }\n",
        "      }\n",
        "      classification_weight: 1.0\n",
        "      localization_weight: 1.0\n",
        "    }\n",
        "    encode_background_as_zeros: true\n",
        "    normalize_loc_loss_by_codesize: true\n",
        "    inplace_batchnorm_update: true\n",
        "    freeze_batchnorm: false\n",
        "  }\n",
        "}\n",
        "train_config {\n",
        "  batch_size: 1\n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    random_crop_image {\n",
        "      min_object_covered: 0.0\n",
        "      min_aspect_ratio: 0.75\n",
        "      max_aspect_ratio: 3.0\n",
        "      min_area: 0.75\n",
        "      max_area: 1.0\n",
        "      overlap_thresh: 0.0\n",
        "    }\n",
        "  }\n",
        "  sync_replicas: true\n",
        "  optimizer {\n",
        "    momentum_optimizer {\n",
        "      learning_rate {\n",
        "        cosine_decay_learning_rate {\n",
        "          learning_rate_base: 0.03999999910593033\n",
        "          total_steps: 25000\n",
        "          warmup_learning_rate: 0.013333000242710114\n",
        "          warmup_steps: 2000\n",
        "        }\n",
        "      }\n",
        "      momentum_optimizer_value: 0.8999999761581421\n",
        "    }\n",
        "    use_moving_average: false\n",
        "  }\n",
        "  fine_tune_checkpoint: \"ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
        "  num_steps: 2000\n",
        "  startup_delay_steps: 0.0\n",
        "  replicas_to_aggregate: 8\n",
        "  max_number_of_boxes: 100\n",
        "  unpad_groundtruth_tensors: false\n",
        "  fine_tune_checkpoint_type: \"detection\"\n",
        "  use_bfloat16: true\n",
        "  fine_tune_checkpoint_version: V2\n",
        "}\n",
        "train_input_reader {\n",
        "  label_map_path: \"labelmap.pbtxt\"\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"train.record\"\n",
        "  }\n",
        "}\n",
        "eval_config {\n",
        "  metrics_set: \"coco_detection_metrics\"\n",
        "  use_moving_averages: false\n",
        "}\n",
        "eval_input_reader {\n",
        "  label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
        "  shuffle: false\n",
        "  num_epochs: 1\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"PATH_TO_BE_CONFIGURED\"\n",
        "  }\n",
        "}\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T05:07:56.868979Z",
          "iopub.status.idle": "2022-01-06T05:07:56.869432Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoMhpJmB6sSn",
        "outputId": "8b785283-c5f8-4f42-b457-89a1dd6ea113"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing pipeline.config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python model_main_tf2.py --model_dir=checkpoints --pipeline_config_path=pipeline.config"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T05:07:56.870363Z",
          "iopub.status.idle": "2022-01-06T05:07:56.870815Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB90I8yy6sSo",
        "outputId": "c38bb698-186b-4a7e-b39b-efa2e0edecae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"model_main_tf2.py\", line 31, in <module>\n",
            "    from object_detection import model_lib_v2\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 29, in <module>\n",
            "    from object_detection import eval_util\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/eval_util.py\", line 36, in <module>\n",
            "    from object_detection.metrics import lvis_evaluation\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/metrics/lvis_evaluation.py\", line 23, in <module>\n",
            "    from lvis import results as lvis_results\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/lvis/__init__.py\", line 5, in <module>\n",
            "    from lvis.vis import LVISVis\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/lvis/vis.py\", line 1, in <module>\n",
            "    import cv2\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/cv2/__init__.py\", line 9, in <module>\n",
            "    from .cv2 import _registerMatType\n",
            "ImportError: cannot import name '_registerMatType' from 'cv2.cv2' (/usr/local/lib/python3.7/dist-packages/cv2/cv2.cpython-37m-x86_64-linux-gnu.so)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "dH7qFMr46sSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "_nppxn5S6sSo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}